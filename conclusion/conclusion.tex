\chapter*{Conclusión y líneas de trabajo futuras}
\addcontentsline{toc}{chapter}{Conclusión}
\markboth{Conclusión}{} % para que la cabecera coincida bien con el capítulo
% Mini mini resumen del report
Hemos visto como desplegar un \textit{cluster} de máquinas utilizando el software  \textit{Apache Hadoop}, 
y posteriormente utilizarlo para desarrollar algoritmos paralelos de \textit{machine learning}. Dichos algoritmos
se han desarrollado tanto en \textit{MapReduce} como en \textit{Spark}.

Respecto a los conocimientos necesarios para abordar este trabajo, del grado en \textbf{Ciencias Matemáticas}
cabe destacar por su especial utilidad las asignaturas de programación paralela, geometría computacional y 
programación declarativa entre otras. Todas ellas pertenecientes al itinerario de \textbf{ciencias de la computación}.
Adicionalmente a estos conocimientos, también ha sido especialmente necesario aprender el funcionamiento
de los sistemas \textit{UNIX} (en particular de \textit{LINUX}), sobre todo su uso a través de la línea de comandos 
(\textit{CLI}, por sus siglas en inglés \textit{Command Line Interface}). 
Si bien no hay una asignatura específica para aprender estos sistemas operativos en la carrera de Matemáticas, 
el libro \cite{unix_programming_environment} es un buen punto de partida para comenzar.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Retomar los objetivos y evaluarlos
\subsection*{Evaluación de los objetivos}
Los objetivos expuestos en la sección de \nameref{objetivos_plan_trabajo} 
se han realizado siguiendo el plan de trabajo establecido. A modo de evaluación vamos a repasarlos:

\begin{itemize}
  \item Instalación de un \textbf{\textit{cluster Hadoop}} de máquinas virtuales.
  \begin{itemize}
    \item[] El despliegue del \textit{cluster} se ha realizado sobre máquinas virtuales usando \textit{Cloudera Manager}
            como herramienta principal. En la \autoref{test_cluster_desplegado} se comprobó como la instalación
            se realizó correctamente y todos los servicios desplegados (\textit{HDFS}, \textit{YARN}...) funcionaban bien.\\
            En esta parte la mayor dificultad radica en la instalación de todos los componentes que necesita 
            \textit{Hadoop} para su correcto funcionamiento, es decir, \textit{Java}, \textit{MySQL}, \textit{NTP}...\\
            Como \textit{Cloudera Manager} es un asistente gráfico, facilita enormemente el trabajo que va por detrás
            ya que lo gestiona automáticamente. Sin embargo, para realizar dicho despliegue conviene tener muy clara
            la teoría detrás de los servicios de \textit{Hadoop}, donde viene muy bien explicada en el libro 
            \cite{White:2009:HDG:1717298}.\\
            Respecto a los \textit{frameworks} de procesamiento que hemos instalado, el proceso ha sido bastante sencillo
            debido a las herramientas de \textit{Cloudera} y al gestor de paquetes de \textit{Python}. Esta parte no
            supuso mayor complicación.
  \end{itemize}
  \item Desarrollo de algoritmos de \textbf{\textit{machine learning}} de manera paralela.
  \begin{itemize}
    \item[] Los algoritmos desarrollados cumplen con las características que todo algoritmo distribuido debe cumplir,
            especialmente en lo que se refiere a la \textbf{escalabilidad}. El incremento de los datos a procesar solo
            penaliza el rendimiento en cuanto a tiempo de ejecución y nunca llega a colapsar el programa. 
            Tanto los algoritmos desarrollados en \textit{MapReduce} como en \textit{Spark} cumplen con dichas 
            condiciones de escalabilidad si bien el diseño de cada uno de ellos es diferente debido a su 
            arquitectura interna.\\
            La clave a la hora de conseguir este objetivo es tener en mente que el diseño de los algoritmos paralelos
            se basa en no guardar variables en memoria que puedan colapsar la capacidad del nodo trabajador.
            El proceso de desarrollo de algoritmos distribuidos implica cambiar la mentalidad a la hora de escribir
            el código ya que los datos se encuentran repartidos en distintas máquinas que funcionan de manera 
            asíncrona. El reto en este objetivo era desarrollar estos algoritmos en lo que a buenas prácticas se refiere.
  \end{itemize} 
\end{itemize}

\clearpage

\subsection*{Líneas de trabajo futuras}
Este proyecto puede servir como base para futuros trabajos relacionados con los temas que aquí se tratan, 
entiendase \textit{Big Data}, \textit{Machine Learning}, \textit{Apache Hadoop}, \textit{Apache Spark}...\\
Como primera línea de trabajo futuro se puede relacionar con temas de \textbf{\textit{Deep Learning}}\index{Deep Learning}, que es una rama encuadrada dentro del \textit{machine learning} 
y está enfocada en las redes neuronales convolucionales, que por su naturaleza estas toman un gran 
tiempo de entrenamiento.\\
Dentro del \textit{deep learning}, se puede avanzar en el estudio y desarrollo de técnicas paralelas para poder
entrenar redes neuronales convolucionales (\textit{CNN}, por sus siglas en inglés \textit{Convolutional Neural Network}) 
en un \textit{cluster} y así reducir los tiempos de ejecución.
En la tabla \autoref{MachineLearningVSDeepLearning} se muestran las principales diferencias conceptuales
entre \textit{machine learning} y \textit{deep learning}.

\begin{table}[!htpb]
  \centering
  \begin{tabular}{|r|c|c|} % tabla
    \hline
    & \textbf{\textit{Machine Learning}} & \textbf{\textit{Deep Learning}} \\ \hline
    Conjunto de entrenamiento & medio & grande \\ \hline
    Ingeniería de características & manual & automática \\ \hline
    Clasificadores disponibles & muchos & pocos \\ \hline
    Tiempo de entrenamiento & medio & grande \\ \hline
  \end{tabular}
   \caption[Diferencias entre \textit{Machine Learning} y \textit{Deep Learning}]
           {Diferencias entre \textit{Machine Learning} y \textit{Deep Learning}}
   \label{MachineLearningVSDeepLearning}
\end{table}

Otra posible línea de investigación reside en el uso de \textbf{\textit{GPU}}\footnote{Graphic Procesing 
Unit}\index{GPU} para la aceleración del proceso de entrenamiento de una red neuronal, y en concreto 
de una \textit{CNN}. 
Este proceso paralelo se puede ejecutar bien sea en una sola máquina (como puede ser un ordenador personal) 
o bien en un \textit{cluster} de máquinas donde cada nodo lleve incorporado una Unidad de Procesamiento Gráfico. \\
Los procesadores gráficos de \href{http://www.nvidia.es/page/home.html}{\textit{NVIDIA}} poseen una 
arquitectura de cálculo paralela llamada \href{http://www.nvidia.es/object/cuda-parallel-computing-es.html}{\textit{CUDA}}
(\url{http://www.nvidia.es/object/cuda-parallel-computing-es.html})
 que permite aprovechar dicha tarjeta gráfica para realizar cómputos. Es especialmente útil en la multiplicación 
de matrices ya que esencialmente una red neuronal se compone de matrices distinguidas en varias capas.
Este trabajo puede servir de base para futuros proyectos acerca de la utilización de \textit{GPU's} en 
\textit{clusters} de máquinas.
\newline

Una tercera línea de investigación posible es la utilización de algoritmos para otros fines de los que
inicialmente fueron destinados. Para la compresión de imágenes se pueden utilizar distintos algoritmos de
\textit{machine learning} como por ejemplo \textit{KMeans} o \textit{PCA}\index{PCA}
\footnote{\textit{Principal Component Analysis}} (vease \cite{DBLP:books/lib/HastieTF09}).\\
Un tipo especial de redes neuronales denominadas autocodificadores o \textit{autoencoders} son aquellas que
tienen 3 capas (una de entrada, una oculta y otra de salida) donde la capa de entrada y de salida son la misma
y la capa oculta posee menos neuronas que las otras dos para así obligar a la red que aprenda a codificar los
datos de entrada en un formato más comprimido.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage

