\begin{abstract}
En este trabajo se aborda el estudio de las tecnologías actuales para el tratamiento
de grandes volúmenes de datos, así como la creación de un \textit{cluster} de máquinas 
utilizando \textit{Apache Hadoop}\texttrademark. Posteriormente, se hace uso de él y de modernas técnicas 
de programación paralela para desarrollar algoritmos de \textit{machine learning} de una manera 
distribuida, escalable y eficiente. Todos estos conceptos y tecnologías se integran dentro de un área de 
estudio heterodoxa que se suele denominar como \hyperref[big_data_def]{\textit{Big Data}}.
\newline

Se detalla el despliegue de un \textbf{\textit{cluster Hadoop}} utilizando una herramienta gráfica 
llamada \textbf{\textit{Cloudera Manager}}. Este software facilita enormemente el trabajo de desplegar un 
\textit{cluster} ya que se gestiona automáticamente la monitorización de los nodos, la creación de 
usuarios, ficheros de configuración y demás tareas.
Cuando el tamaño del \textit{cluster} se vuelve grande o son muchos los servicios instalados en él,
esta es la mejor opción para desplegarlo. \textit{Cloudera} proporciona dos maneras para dicho despliegue
que se explican de manera general en \autoref{apendix:cloudera}.
\newline

Este trabajo se enfoca también en desarrollar buenas prácticas en lo que a computación distribuida 
se refiere y se comparan distintos enfoques para la resolución de un mismo problema.
Estos enfoques permiten entender mejor los retos de la computación paralela y la depuración 
de los algoritmos distribuidos de una manera general, no centrándose específicamente en el \textit{machine learning}.\\
Los algoritmos de \textbf{\textit{machine learning}} se han desarrollado utilizando dos enfoques de programación 
paralela, usando el ya clásico paradigma de programación \textit{MapReduce},  o bien utilizando el paradigma 
\textit{Spark}, más moderno y con una cierta orientación de programación funcional. \\
La utilización de uno u otro enfoque depende en gran parte de la arquitectura del algoritmo, esto es, 
para algoritmos iterativos es mas conveniente usar \textit{Spark} ya que permite persistir los datos en 
memoria y por lo tanto reduce enormemente el tiempo de ejecución del algoritmo. Por el contrario, un 
algoritmo como puede ser calcular la media y la varianza de un conjunto de datos, no requiere mas que 
una pasada al completo del \textit{dataset}, por lo que con una fase \textit{map} y otra 
\textit{reduce} es suficiente para calcular dichas variables.
\newline

Se tendrá especial atención a la escalabilidad de los algoritmos y el consumo de recursos de un proceso 
(memoria y \textit{CPU}) ya que un buen rendimiento del algoritmo es clave en la computación distribuida.
Los distintos enfoques a la hora de programar un algoritmo se basan en reducir los posibles cuellos 
de botella que se puedan producir con los datos. Esto es, el uso de \textit{combiners} en trabajos 
\textit{MapReduce}, ordenes que desencadenen \textit{shuffles}\footnote{movimiento de datos entre 
nodos a través de la red} en \textit{Spark}, etc.\\
Al final de cada sección se ha incluido el \textbf{código fuente} de cada algoritmo desarrollado.
\newline

Los algoritmos programados usando el paradigma de programación \textit{MapReduce} han sido 
desarrollados usando la librería \textit{mrjob} del lenguaje de programación \textit{Python}\texttrademark . El resto de algoritmos se han desarrollado utilizando el \textit{framework} \textit{Spark} mediante \textit{Python}, aunque
también esta disponible en lenguajes como \textit{Java}, \textit{Scala} o \textit{R}.
Se hace uso de las librerías \textit{open source} \textit{numpy}, \textit{scipy}, 
\textit{matplotlib} y \textit{sklearn}, siempre que sean útiles para el propósito del desarrollo 
y la visualización de los datos.
\newline

Todo el código fuente desarrollado se encuentra disponible en mi página de 
\href{https://github.com/davidRetana}{GitHub}.\\ 
(\url{https://github.com/davidRetana})

\end{abstract}

\selectlanguage{english}
\setcounter{page}{7} %porque al cambiar de lenguaje se resetea el contador de paginas
\begin{abstract}
This paper deals with the study of current technologies for the treatment
of large volumes of data, as well as the deployment of a machine's cluster
using Apache Hadoop. Afterwards, we will have use of this cluster and modern parallel programming tecniques 
to develop machine learning algorithms in a distributed, scalable and efficient way.
All of these concepts and technologies are integrated within a study area called 
\hyperref[big_data_def]{\textit{Big Data}}.
\newline

The deployment of a \textbf{\textit{Hadoop cluster}} is detailed using a graphical tool
called \textbf{\textit{Cloudera Manager}}. This software greatly facilitates the work of deploying a
\textit{cluster} beacuse it automatically manages the monitoring of the nodes, the creation of
users, configuration files and other tasks.
When the size of the \textit{cluster} becomes large or many services are installed on it,
this is the best option to deploy it. Cloudera provides two ways for such deployment
which are generally explained in \autoref{apendix:cloudera}.
\newline

This work also focuses on the development of good practices in what a distributed computing
is referred to and compared to other approaches to solving the same problem.
These approaches allow a better understanding of the challenges of parallel computing and debugging
of the algorithms distributed in a general way, not focusing specifically on machine learning. \\
\textbf{Machine learning} algorithms have been developed using parallel programming approaches, 
either using the classic \textbf{\textit{MapReduce}} programming paradigm or using
\textbf{\textit{Spark}} programming paradigm, more modern and functional programming oriented. \\
Using one or other approach depends to a great extent on the architecture of the algorithm, that is,
for iterative algorithms it is more convenient to use \textit{Spark} since it allows to persist the data in
memory and thereby greatly reduce the execution time of the algorithm. On the contrary, a
algorithm as it can calculate the mean and the variance of a data set, does not require more than
a complete pass of the \textit{dataset}, so with a map phase and another
\textit{reduce} phase is sufficient to calculate these variables.
\newline

Special attention is given to the scalability of the algorithms and the resource consumption of a process
(memory and CPU) since a good performance of the algorithm is a key part in distributed computing.
The different approaches to programming an algorithm are based on reducing possible bottleneck
that can be produced with the data. That is, the use of \textit{combiners} in \textit{MapReduce} jobs, 
commands that trigger \textit{shuffles}\footnote{data movement between nodes through the network} in 
\textit{Spark}, etc. \\
At the end of each section the \textbf{source code} of each developed algorithm has been included.
\newline

The algorithms programmed using the \textit{MapReduce} programming paradigm have been
developed using the \textit{mrjob} library of the \textit{Python}\texttrademark programming language. 
The remaining algorithms have been developed using \textit{Spark} framework throught Python, although
also Spark is available in other lenguages such as Java, Scala or R.
This report makes use of the open source libraries \textit{numpy}, \textit{scipy},
\textit{matplotlib} and \textit{sklearn}, as long as it is useful for the purpose of development
and the visualization of the data.
\newline

All the source code developed is available on my \href{https://github.com/davidRetana}{GitHub} page.\\
(\url{https://github.com/davidRetana})

\end{abstract}
\selectlanguage{spanish}
\setcounter{page}{8} %porque al cambiar de lenguaje se resetea el contador de paginas